name: Concatenate Audio Chunks and Upload to Cloudinary

on:
  push:
    paths:
      - 'public/data/uploads/*.json'

jobs:
  concat-upload:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Read upload info JSON
        id: uploadinfo
        run: |
          # Try to get the latest added/modified JSON file in uploads
          json_file=$(git diff --name-only ${{ github.event.before }} ${{ github.sha }} | grep 'public/data/uploads/' | tail -n1)
          # Fallback: list the most recent file if above fails
          if [ -z "$json_file" ]; then
            json_file=$(ls -t public/data/uploads/*.json | head -n1)
          fi
          if [ ! -f "$json_file" ]; then
            echo "No upload info JSON file found. Exiting."
            exit 1
          fi
          echo "JSON_FILE=$json_file" >> $GITHUB_ENV
          cat "$json_file"
          uploadId=$(jq -r .uploadId "$json_file")
          totalChunks=$(jq -r .totalChunks "$json_file")
          extension=$(jq -r .fileExtension "$json_file")
          if [ -z "$extension" ] || [ "$extension" = "null" ]; then
            echo "Extension is missing or null in $json_file. Exiting."
            exit 1
          fi
          echo "UPLOAD_ID=$uploadId" >> $GITHUB_ENV
          echo "TOTAL_CHUNKS=$totalChunks" >> $GITHUB_ENV
          echo "EXTENSION=$extension" >> $GITHUB_ENV

          # Check if upload is already completed
          progress=$(jq -r .progress "$json_file" 2>/dev/null || echo "null")
          existingHlsUrl=$(jq -r .hlsUrl "$json_file" 2>/dev/null || echo "null")

          if [ "$progress" = "complete" ] && [ "$existingHlsUrl" != "null" ]; then
            echo "Upload already completed with HLS URL: $existingHlsUrl"
            echo "SKIP_CHUNK_PROCESSING=true" >> $GITHUB_ENV
          else
            echo "Processing new upload..."
            echo "SKIP_CHUNK_PROCESSING=false" >> $GITHUB_ENV
          fi

      - name: Download audio chunks from Cloudinary
        if: env.SKIP_CHUNK_PROCESSING != 'true'
        run: |
          for i in $(seq -f "%04g" 0 $(($TOTAL_CHUNKS - 1))); do
            curl -L -o chunk-$i.$EXTENSION "https://res.cloudinary.com/${{ secrets.CLOUDINARY_CLOUD_NAME }}/raw/upload/podcast/chunks/$UPLOAD_ID-chunk-$i.$EXTENSION"
          done

      - name: List and verify chunk files
        if: env.SKIP_CHUNK_PROCESSING != 'true'
        run: |
          ls -lh chunk-*.$EXTENSION || echo "No chunks downloaded"
          for f in chunk-*.$EXTENSION; do
            if [ ! -s "$f" ]; then
              echo "Chunk $f is missing or empty!";
              exit 1;
            fi
          done
          echo "All chunk files are present and non-empty."

      - name: Concatenate chunks as binary
        if: env.SKIP_CHUNK_PROCESSING != 'true'
        run: |
          cat chunk-*.$EXTENSION > full_upload.$EXTENSION

      - name: Install FFmpeg
        if: env.SKIP_CHUNK_PROCESSING != 'true'
        run: sudo apt-get update && sudo apt-get install -y ffmpeg

      - name: Convert concatenated file to HLS (streamable format)
        if: env.SKIP_CHUNK_PROCESSING != 'true'
        run: |
          mkdir -p hls
          ffmpeg -y -i full_upload.$EXTENSION -codec:a aac -b:a 128k -f hls -hls_time 10 -hls_playlist_type vod -hls_segment_filename "hls/segment%03d.aac" hls/playlist.m3u8

      - name: Upload HLS files to Cloudinary
        if: env.SKIP_CHUNK_PROCESSING != 'true'
        env:
          CLOUDINARY_CLOUD_NAME: ${{ secrets.CLOUDINARY_CLOUD_NAME }}
          CLOUDINARY_API_KEY: ${{ secrets.CLOUDINARY_API_KEY }}
          CLOUDINARY_API_SECRET: ${{ secrets.CLOUDINARY_API_SECRET }}
        run: |
          pip install cloudinary
          for f in hls/*; do
            base=$(basename "$f")
            python -c "import cloudinary; import cloudinary.uploader; cloudinary.config(cloud_name='${{ secrets.CLOUDINARY_CLOUD_NAME }}', api_key='${{ secrets.CLOUDINARY_API_KEY }}', api_secret='${{ secrets.CLOUDINARY_API_SECRET }}'); result = cloudinary.uploader.upload('$f', resource_type='raw', public_id='podcast/final/${UPLOAD_ID}/$base'); print(result)"
          done

      - name: Update playlists.json with HLS playlist URL
        env:
          GITHUB_TOKEN: ${{ secrets.CH_TOKEN }}
        run: |
          pip install jq
          PLAYLISTS_FILE="playlists.json"
          if [ ! -f "$PLAYLISTS_FILE" ]; then
            curl -L -o "$PLAYLISTS_FILE" "https://raw.githubusercontent.com/bl5ck/magnificent-team-podcast/main/playlists.json"
          fi
          if [ ! -f "$PLAYLISTS_FILE" ]; then
            echo "Error: $PLAYLISTS_FILE does not exist and could not be downloaded."
            exit 1
          fi

          # Check if upload JSON already has progress and HLS URL
          progress=$(jq -r .progress "$JSON_FILE" 2>/dev/null || echo "null")
          existingHlsUrl=$(jq -r .hlsUrl "$JSON_FILE" 2>/dev/null || echo "null")

          if [ "$progress" = "complete" ] && [ "$existingHlsUrl" != "null" ]; then
            echo "Upload already completed with HLS URL: $existingHlsUrl"
            hlsUrl="$existingHlsUrl"
          else
            hlsUrl="https://res.cloudinary.com/${{ secrets.CLOUDINARY_CLOUD_NAME }}/raw/upload/podcast/final/$UPLOAD_ID/playlist.m3u8"
          fi

          playlistId=$(jq -r .playlistId "$JSON_FILE")
          episodeId=$(jq -r .episodeId "$JSON_FILE")
          episodeTitle=$(jq -r .episodeTitle "$JSON_FILE")
          episodeDescription=$(jq -r .episodeDescription "$JSON_FILE")

          # Create new episode object
          newEpisode=$(jq -n \
            --arg id "$episodeId" \
            --arg title "$episodeTitle" \
            --arg description "$episodeDescription" \
            --arg audioUrl "$hlsUrl" \
            --arg publishDate "$(date +%Y-%m-%d)" \
            '{
              id: $id,
              title: $title,
              description: $description,
              audioUrl: $audioUrl,
              publishDate: $publishDate,
              processingStatus: "complete",
              thumbnailUrl: null,
              duration: "00:00"
            }')

          # Add episode to playlist
          tmpfile=$(mktemp)
          jq --arg pid "$playlistId" --argjson episode "$newEpisode" \
            '(.[] | select(.id == $pid).episodes) += [$episode]' \
            "$PLAYLISTS_FILE" > "$tmpfile" && mv "$tmpfile" "$PLAYLISTS_FILE"

          contentBase64=$(base64 -w 0 "$PLAYLISTS_FILE")
          api_url="https://api.github.com/repos/bl5ck/magnificent-team-podcast/contents/playlists.json"
          fileSha=$(curl -s -H "Authorization: Bearer $GITHUB_TOKEN" "$api_url" | jq -r .sha)
          payload="{\"message\": \"Add new episode with HLS URL [skip ci]\", \"content\": \"$contentBase64\""
          if [ "$fileSha" != "null" ] && [ -n "$fileSha" ]; then
            payload="$payload, \"sha\": \"$fileSha\""
          fi
          payload="$payload}"
          curl -X PUT -H "Authorization: Bearer $GITHUB_TOKEN" -H "Content-Type: application/json" -d "$payload" "$api_url"

      - name: Update upload JSON with completion status
        if: env.SKIP_CHUNK_PROCESSING != 'true'
        env:
          GITHUB_TOKEN: ${{ secrets.CH_TOKEN }}
        run: |
          # Update the upload JSON with progress and HLS URL
          tmpfile=$(mktemp)
          jq --arg progress "complete" --arg hlsUrl "$hlsUrl" \
            '. + {progress: $progress, hlsUrl: $hlsUrl}' \
            "$JSON_FILE" > "$tmpfile" && mv "$tmpfile" "$JSON_FILE"

          contentBase64=$(base64 -w 0 "$JSON_FILE")
          api_url="https://api.github.com/repos/bl5ck/magnificent-team-podcast/contents/$JSON_FILE"
          fileSha=$(curl -s -H "Authorization: Bearer $GITHUB_TOKEN" "$api_url" | jq -r .sha)
          payload="{\"message\": \"Update upload JSON with completion status [skip ci]\", \"content\": \"$contentBase64\""
          if [ "$fileSha" != "null" ] && [ -n "$fileSha" ]; then
            payload="$payload, \"sha\": \"$fileSha\""
          fi
          payload="$payload}"
          curl -X PUT -H "Authorization: Bearer $GITHUB_TOKEN" -H "Content-Type: application/json" -d "$payload" "$api_url"

      - name: Delete chunk files from Cloudinary
        if: env.SKIP_CHUNK_PROCESSING != 'true'
        env:
          CLOUDINARY_CLOUD_NAME: ${{ secrets.CLOUDINARY_CLOUD_NAME }}
          CLOUDINARY_API_KEY: ${{ secrets.CLOUDINARY_API_KEY }}
          CLOUDINARY_API_SECRET: ${{ secrets.CLOUDINARY_API_SECRET }}
        run: |
          pip install cloudinary
          for i in $(seq -f "%04g" 0 $(($TOTAL_CHUNKS - 1))); do
            chunk_name="podcast/chunks/${UPLOAD_ID}-chunk-$i.${EXTENSION}"
            python -c "import cloudinary; import cloudinary.uploader; cloudinary.config(cloud_name='${{ secrets.CLOUDINARY_CLOUD_NAME }}', api_key='${{ secrets.CLOUDINARY_API_KEY }}', api_secret='${{ secrets.CLOUDINARY_API_SECRET }}'); cloudinary.uploader.destroy('$chunk_name', resource_type='raw')"
          done

      - name: Cleanup
        if: env.SKIP_CHUNK_PROCESSING != 'true'
        run: rm -f chunk-*.$EXTENSION full_upload.$EXTENSION output.mp3 output.$EXTENSION && rm -rf hls
